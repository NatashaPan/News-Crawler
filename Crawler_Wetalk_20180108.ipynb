{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效能優化＿實驗區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import concurrent.futures\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START = datetime.now()\n",
    "\n",
    "def stop_watch():\n",
    "    \"\"\"\n",
    "    A stop_watch to time a code segment \n",
    "    in order to monitor performance\n",
    "    \"\"\"\n",
    "    global START  #<----------------------------------不加global修飾詞會出現UnboundLocalError，但加了感覺很暴力XD\n",
    "    END = datetime.now()\n",
    "    timeSpent = str(END - START) \n",
    "\n",
    "    START = END\n",
    "    return timeSpent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests.get = 0:00:02.783487\n",
      "tmp = 0:00:00.205710\n",
      "post_urls = 0:00:00.000184\n",
      "requests.get = 0:00:01.794263\n",
      "tmp = 0:00:00.172709\n",
      "post_urls = 0:00:00.000141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['http://www.wetalk.tw/thread-70892-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70887-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70647-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70829-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70802-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70549-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70766-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70689-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70674-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70318-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70635-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70584-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70565-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70573-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70551-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70520-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70518-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70488-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70486-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70471-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70297-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70467-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70450-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70424-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70376-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70371-1-1.html',\n",
       " 'http://www.wetalk.tw/thread-70329-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70304-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70181-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70277-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70286-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70250-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70239-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-57466-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70224-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70228-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70213-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70204-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69205-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70131-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70122-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70046-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-70031-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69996-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69935-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-44167-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69864-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69760-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69906-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69806-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69587-1-2.html',\n",
       " 'http://www.wetalk.tw/thread-69551-1-2.html']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START = datetime.now()\n",
    "\n",
    "post_urls = []\n",
    "for page in range(1, 3): #總共310頁 #想測試一下效能看是否能優化,因為我用了tmp處理，是否等於寫了兩次？ Ans:不會，瓶頸其實在於requests.get(URL)\n",
    "    URL = \"https://www.wetalk.tw/forum.php?mod=forumdisplay&fid=2&page={}\".format(page)    \n",
    "    resp = requests.get(URL)\n",
    "    print('requests.get = ' + stop_watch())\n",
    "    soup = BeautifulSoup(resp.text, \"html5lib\")\n",
    "    tmp = []\n",
    "    tmp += [a.get('href') for a in soup.select('tbody > tr > th > a.xst')]\n",
    "    print('tmp = ' + stop_watch())\n",
    "    post_urls += tmp[2:]\n",
    "    print('post_urls = ' + stop_watch())\n",
    "post_urls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r.get與resp_c.text  = 0:00:02.269349\n",
      "all except comments = 0:00:00.009149\n",
      "comments            = 0:00:00.081744\n",
      "write into the file = 0:00:00.000129\n",
      "r.get與resp_c.text  = 0:00:01.718565\n",
      "all except comments = 0:00:00.002914\n",
      "comments            = 0:00:00.005718\n",
      "write into the file = 0:00:00.003060\n",
      "r.get與resp_c.text  = 0:00:01.507018\n",
      "all except comments = 0:00:00.003052\n",
      "comments            = 0:00:00.003413\n",
      "write into the file = 0:00:00.000311\n",
      "r.get與resp_c.text  = 0:00:01.235514\n",
      "all except comments = 0:00:00.002968\n",
      "comments            = 0:00:00.003389\n",
      "write into the file = 0:00:00.000791\n",
      "r.get與resp_c.text  = 0:00:02.082076\n",
      "all except comments = 0:00:00.003273\n",
      "comments            = 0:00:00.003559\n",
      "write into the file = 0:00:00.000266\n",
      "r.get與resp_c.text  = 0:00:02.346113\n",
      "all except comments = 0:00:00.003423\n",
      "comments            = 0:00:00.010516\n",
      "write into the file = 0:00:00.000801\n",
      "r.get與resp_c.text  = 0:00:01.409996\n",
      "all except comments = 0:00:00.004374\n",
      "comments            = 0:00:00.021695\n",
      "write into the file = 0:00:00.000268\n",
      "r.get與resp_c.text  = 0:00:01.584876\n",
      "all except comments = 0:00:00.004339\n",
      "comments            = 0:00:00.025385\n",
      "write into the file = 0:00:00.000942\n",
      "r.get與resp_c.text  = 0:00:01.845738\n",
      "all except comments = 0:00:00.003111\n",
      "comments            = 0:00:00.007120\n",
      "write into the file = 0:00:00.000355\n",
      "r.get與resp_c.text  = 0:00:02.219261\n",
      "all except comments = 0:00:00.005068\n",
      "comments            = 0:00:00.023109\n",
      "write into the file = 0:00:00.000765\n",
      "r.get與resp_c.text  = 0:00:02.095703\n",
      "all except comments = 0:00:00.005081\n",
      "comments            = 0:00:00.048161\n",
      "write into the file = 0:00:00.000122\n",
      "r.get與resp_c.text  = 0:00:01.444599\n",
      "all except comments = 0:00:00.003944\n",
      "comments            = 0:00:00.021843\n",
      "write into the file = 0:00:00.001320\n",
      "r.get與resp_c.text  = 0:00:01.685998\n",
      "all except comments = 0:00:00.003247\n",
      "comments            = 0:00:00.010729\n",
      "write into the file = 0:00:00.000252\n",
      "r.get與resp_c.text  = 0:00:01.399961\n",
      "all except comments = 0:00:00.002876\n",
      "comments            = 0:00:00.003894\n",
      "write into the file = 0:00:00.002564\n",
      "r.get與resp_c.text  = 0:00:02.219585\n",
      "all except comments = 0:00:00.006344\n",
      "comments            = 0:00:00.052074\n",
      "write into the file = 0:00:00.000133\n",
      "r.get與resp_c.text  = 0:00:01.855018\n",
      "all except comments = 0:00:00.003071\n",
      "comments            = 0:00:00.007014\n",
      "write into the file = 0:00:00.000938\n",
      "r.get與resp_c.text  = 0:00:01.789365\n",
      "all except comments = 0:00:00.002729\n",
      "comments            = 0:00:00.003231\n",
      "write into the file = 0:00:00.000279\n",
      "r.get與resp_c.text  = 0:00:01.510908\n",
      "all except comments = 0:00:00.002663\n",
      "comments            = 0:00:00.003158\n",
      "write into the file = 0:00:00.000734\n",
      "r.get與resp_c.text  = 0:00:01.458797\n",
      "all except comments = 0:00:00.002825\n",
      "comments            = 0:00:00.003300\n",
      "write into the file = 0:00:00.000292\n",
      "r.get與resp_c.text  = 0:00:02.353361\n",
      "all except comments = 0:00:00.002631\n",
      "comments            = 0:00:00.003150\n",
      "write into the file = 0:00:00.000779\n",
      "r.get與resp_c.text  = 0:00:01.464869\n",
      "all except comments = 0:00:00.003154\n",
      "comments            = 0:00:00.006494\n",
      "write into the file = 0:00:00.000288\n",
      "r.get與resp_c.text  = 0:00:02.002916\n",
      "all except comments = 0:00:00.003727\n",
      "comments            = 0:00:00.014854\n",
      "write into the file = 0:00:00.000714\n",
      "r.get與resp_c.text  = 0:00:00.906145\n",
      "all except comments = 0:00:00.007294\n",
      "comments            = 0:00:00.069791\n",
      "write into the file = 0:00:00.000123\n",
      "r.get與resp_c.text  = 0:00:01.346382\n",
      "all except comments = 0:00:00.004358\n",
      "comments            = 0:00:00.015712\n",
      "write into the file = 0:00:00.000868\n",
      "r.get與resp_c.text  = 0:00:01.031106\n",
      "all except comments = 0:00:00.002579\n",
      "comments            = 0:00:00.003443\n",
      "write into the file = 0:00:00.000339\n",
      "r.get與resp_c.text  = 0:00:02.092075\n",
      "all except comments = 0:00:00.005585\n",
      "comments            = 0:00:00.049056\n",
      "write into the file = 0:00:00.000768\n",
      "r.get與resp_c.text  = 0:00:02.060029\n",
      "all except comments = 0:00:00.006658\n",
      "comments            = 0:00:00.061284\n",
      "write into the file = 0:00:00.000125\n",
      "r.get與resp_c.text  = 0:00:01.288431\n",
      "all except comments = 0:00:00.002689\n",
      "comments            = 0:00:00.003198\n",
      "write into the file = 0:00:00.000840\n",
      "r.get與resp_c.text  = 0:00:01.537234\n",
      "all except comments = 0:00:00.003535\n",
      "comments            = 0:00:00.011221\n",
      "write into the file = 0:00:00.000276\n",
      "r.get與resp_c.text  = 0:00:01.637809\n",
      "all except comments = 0:00:00.007117\n",
      "comments            = 0:00:00.014159\n",
      "write into the file = 0:00:00.002324\n",
      "r.get與resp_c.text  = 0:00:02.273465\n",
      "all except comments = 0:00:00.006331\n",
      "comments            = 0:00:00.074974\n",
      "write into the file = 0:00:00.000208\n",
      "r.get與resp_c.text  = 0:00:01.519689\n",
      "all except comments = 0:00:00.003391\n",
      "comments            = 0:00:00.010644\n",
      "write into the file = 0:00:00.000805\n",
      "r.get與resp_c.text  = 0:00:02.450888\n",
      "all except comments = 0:00:00.003605\n",
      "comments            = 0:00:00.006820\n",
      "write into the file = 0:00:00.000145\n",
      "r.get與resp_c.text  = 0:00:01.520476\n",
      "all except comments = 0:00:00.005285\n",
      "comments            = 0:00:00.010556\n",
      "write into the file = 0:00:00.000799\n",
      "r.get與resp_c.text  = 0:00:01.810737\n",
      "all except comments = 0:00:00.003348\n",
      "comments            = 0:00:00.010011\n",
      "write into the file = 0:00:00.000282\n",
      "r.get與resp_c.text  = 0:00:02.074497\n",
      "all except comments = 0:00:00.002715\n",
      "comments            = 0:00:00.006777\n",
      "write into the file = 0:00:00.000832\n",
      "r.get與resp_c.text  = 0:00:01.687049\n",
      "all except comments = 0:00:00.003388\n",
      "comments            = 0:00:00.011364\n",
      "write into the file = 0:00:00.000292\n",
      "r.get與resp_c.text  = 0:00:01.712548\n",
      "all except comments = 0:00:00.008484\n",
      "comments            = 0:00:00.092059\n",
      "write into the file = 0:00:00.002999\n",
      "r.get與resp_c.text  = 0:00:01.502918\n",
      "all except comments = 0:00:00.003940\n",
      "comments            = 0:00:00.020751\n",
      "write into the file = 0:00:00.000355\n",
      "r.get與resp_c.text  = 0:00:01.342091\n",
      "all except comments = 0:00:00.004406\n",
      "comments            = 0:00:00.008230\n",
      "write into the file = 0:00:00.001098\n",
      "r.get與resp_c.text  = 0:00:01.882936\n",
      "all except comments = 0:00:00.003178\n",
      "comments            = 0:00:00.006729\n",
      "write into the file = 0:00:00.000151\n",
      "r.get與resp_c.text  = 0:00:01.576185\n",
      "all except comments = 0:00:00.002991\n",
      "comments            = 0:00:00.006536\n",
      "write into the file = 0:00:00.000732\n",
      "r.get與resp_c.text  = 0:00:01.322140\n",
      "all except comments = 0:00:00.006039\n",
      "comments            = 0:00:00.057833\n",
      "write into the file = 0:00:00.000114\n",
      "r.get與resp_c.text  = 0:00:01.356965\n",
      "all except comments = 0:00:00.002537\n",
      "comments            = 0:00:00.003183\n",
      "write into the file = 0:00:00.000704\n",
      "r.get與resp_c.text  = 0:00:01.602930\n",
      "all except comments = 0:00:00.003936\n",
      "comments            = 0:00:00.020217\n",
      "write into the file = 0:00:00.000256\n",
      "r.get與resp_c.text  = 0:00:01.468702\n",
      "all except comments = 0:00:00.004486\n",
      "comments            = 0:00:00.030532\n",
      "write into the file = 0:00:00.000776\n",
      "r.get與resp_c.text  = 0:00:02.238950\n",
      "all except comments = 0:00:00.005700\n",
      "comments            = 0:00:00.060405\n",
      "write into the file = 0:00:00.000120\n",
      "r.get與resp_c.text  = 0:00:01.322665\n",
      "all except comments = 0:00:00.002769\n",
      "comments            = 0:00:00.003357\n",
      "write into the file = 0:00:00.001325\n",
      "r.get與resp_c.text  = 0:00:02.078755\n",
      "all except comments = 0:00:00.005679\n",
      "comments            = 0:00:00.080084\n",
      "write into the file = 0:00:00.000293\n",
      "r.get與resp_c.text  = 0:00:01.503119\n",
      "all except comments = 0:00:00.002653\n",
      "comments            = 0:00:00.003994\n",
      "write into the file = 0:00:00.000873\n",
      "r.get與resp_c.text  = 0:00:01.648903\n",
      "all except comments = 0:00:00.005117\n",
      "comments            = 0:00:00.029920\n",
      "write into the file = 0:00:00.000112\n",
      "r.get與resp_c.text  = 0:00:01.757288\n",
      "all except comments = 0:00:00.003135\n",
      "comments            = 0:00:00.003655\n",
      "write into the file = 0:00:00.000786\n"
     ]
    }
   ],
   "source": [
    "START = datetime.now()\n",
    "\n",
    "news_list = []\n",
    "count = 0\n",
    "\n",
    "for url in post_urls:\n",
    "    news = {}\n",
    "    resp_c = requests.get(url)\n",
    "    soup_c = BeautifulSoup(resp_c.text, 'html5lib')   \n",
    "    print('requests.get與resp_c.text  = ' + stop_watch())\n",
    "    \n",
    "    news[\"title\"]    = soup_c.select(\"h1.ts\")[0].text.replace('\\n','')\n",
    "    news[\"datetime\"] = soup_c.select('span.date-show-info')[0].text.replace('發表','').strip()\n",
    "    news[\"reporter\"] = soup_c.select('a[itemprop=\"author\"]')[0].text\n",
    "    news[\"media\"]    = \"wetalk\"\n",
    "    news[\"category\"] = \"Forum\"\n",
    "    news[\"hash\"]     = hash(resp.text)\n",
    "    news[\"url\"]      = url\n",
    "    news[\"content\"]  = soup_c.select(\"td.t_f > article\")[0].text.replace('\\n','').replace('發表','').strip()\n",
    "    news[\"comments\"] = []\n",
    "    print('all except comments = ' + stop_watch())\n",
    "    \n",
    "    for i in range(len(soup_c.select(\"td.info-post-td > a\"))):\n",
    "        news[\"comments\"].append({})   \n",
    "        news[\"comments\"][i][\"comment_content\"] = \"\".join([p.text for p in soup_c.select('[id^=\"postmessage_\"] > div[align=\"left\"]')])\n",
    "        news[\"comments\"][i][\"datetime\"] = soup_c.select(\"span.date-show-info\")[0].text.replace('\\n','').replace('發表','').strip()\n",
    "        news[\"comments\"][i][\"user_id\"] = soup_c.select(\"td.info-post-td > a\")[0].text\n",
    "    print('comments            = ' + stop_watch())\n",
    "    \n",
    "    news_list.append(news)\n",
    "    count+=1\n",
    "    if 0 == count%2:  #林冠廷說0寫在前面比較好？原因他忘記了???\n",
    "        with open(\"./News_Crawler/wetalk/wetalk_%s.txt\"%count, 'w', encoding='UTF-8') as f:\n",
    "            jd = json.dumps(news_list, ensure_ascii=False, indent=4)\n",
    "            f.write(jd)\n",
    "            news_list[:] = [] #聰明的作法，不然就要使用暴力的global修飾詞指派全域變數news_list\n",
    "    print('write into the file = ' + stop_watch())\n",
    "    #測測看用count還有length熟快熟慢～～～\n",
    "\n",
    "#     print(news)\n",
    "    \n",
    "\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to cathy:\n",
    "#這裏小段程式邏輯有問題xD len('tbody > tr > th > a.xst')指的是'字串'的長度喔ＸＤＤ'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 模組化＿實驗區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import concurrent.futures\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_watch():\n",
    "    \"\"\"\n",
    "    A stop_watch to time a code segment \n",
    "    in order to monitor performance\n",
    "    \"\"\"\n",
    "    global START  #<----------------------------------不加global修飾詞會出現UnboundLocalError，但加了感覺很暴力XD\n",
    "    END = datetime.now()\n",
    "    timeSpent = str(END - START) \n",
    "\n",
    "    START = END\n",
    "    return timeSpent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url_links(page, post_urls):  \n",
    "    \"\"\"\n",
    "    Read through HTML content and returns a list of url_links\n",
    "    of each post in the category \"politics\" at Wetalk.tw\n",
    "    \"\"\"\n",
    "    URL = \"https://www.wetalk.tw/forum.php?mod=forumdisplay&fid=2&page={}\".format(page)    \n",
    "    resp = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html5lib\")\n",
    "    tmp_urls = []\n",
    "    tmp_urls.append([a.get('href') for a in soup.select('tbody > tr > th > a.xst')])\n",
    "    post_urls += tmp_urls[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_posts_info(post_urls):\n",
    "    \"\"\"\n",
    "    Save infomations of the post to a dictionary named \"news\",\n",
    "    then append \"news\" to the \"news_list\"\n",
    "    \"\"\"\n",
    "    news_list = []\n",
    "    count = 0\n",
    "\n",
    "    for url in post_urls:\n",
    "        news = {}\n",
    "        resp_c = requests.get(url)\n",
    "        soup_c = BeautifulSoup(resp_c.text, 'html5lib')   \n",
    "\n",
    "        news[\"title\"]    = soup_c.select(\"h1.ts\")[0].text.replace('\\n','')\n",
    "        news[\"datetime\"] = soup_c.select('span.date-show-info')[0].text.replace('發表','').strip()\n",
    "        news[\"reporter\"] = soup_c.select('a[itemprop=\"author\"]')[0].text\n",
    "        news[\"media\"]    = \"wetalk\"\n",
    "        news[\"category\"] = \"Forum\"\n",
    "        news[\"hash\"]     = hash(resp_c.text)\n",
    "        news[\"url\"]      = url\n",
    "        news[\"content\"]  = soup_c.select(\"td.t_f > article\")[0].text.replace('\\n','').replace('發表','').strip()\n",
    "        news[\"comments\"] = []\n",
    "        for i in range(len(soup_c.select(\"td.info-post-td > a\"))):\n",
    "            news[\"comments\"].append({})   \n",
    "            news[\"comments\"][i][\"comment_content\"] = \"\".join([p.text for p in soup_c.select('[id^=\"postmessage_\"] > div[align=\"left\"]')])\n",
    "            news[\"comments\"][i][\"datetime\"] = soup_c.select(\"span.date-show-info\")[0].text.replace('\\n','').replace('發表','').strip()\n",
    "            news[\"comments\"][i][\"user_id\"] = soup_c.select(\"td.info-post-td > a\")[0].text\n",
    "        news_list.append(news)\n",
    "        count += 1\n",
    "        if 0 == count%2:  #這裏改成100，每100個post輸出一次\n",
    "            output_as_json(count, 'wetalk', news_list)\n",
    "            news_list[:] = []\n",
    "            print('輸出一個檔案囉～')\n",
    "\n",
    "def output_as_json(index, media, x):  \n",
    "    \"\"\"\n",
    "    Write data in json format into .txt files\n",
    "    \"\"\"\n",
    "    with open(\"./News_Crawler/{}/{}_{}.txt\".format(media, media, index), 'w', encoding='UTF-8') as f:\n",
    "        jd = json.dumps(x, ensure_ascii=False, indent=4)\n",
    "        f.write(jd)\n",
    "\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    urls = get_url_links()\n",
    "    save_posts_info(urls)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "main = 0:00:42.852742\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":        \n",
    "    START = datetime.now()\n",
    "    main()\n",
    "    print('main = ' + stop_watch()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#還沒加上class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多執行緒＿實驗區 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_watch():\n",
    "    \"\"\"\n",
    "    A stop_watch to time a code segment \n",
    "    in order to monitor performance\n",
    "    \"\"\"\n",
    "    global START  #<----------------------------------不加global修飾詞會出現UnboundLocalError，但加了感覺很暴力XD\n",
    "    END = datetime.now()\n",
    "    timeSpent = str(END - START) \n",
    "\n",
    "    START = END\n",
    "    return timeSpent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url_links(page, post_urls):  \n",
    "    \"\"\"\n",
    "    Read through HTML content and returns a list of url_links\n",
    "    of each post in the category \"politics\" at Wetalk.tw\n",
    "    \"\"\"\n",
    "    URL = \"https://www.wetalk.tw/forum.php?mod=forumdisplay&fid=2&page={}\".format(page)    \n",
    "    resp = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html5lib\")\n",
    "    tmp_urls = []\n",
    "    tmp_urls.extend([a.get('href') for a in soup.select('tbody > tr > th > a.xst')])\n",
    "    post_urls += tmp_urls[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_posts_info(url, news_list, count):\n",
    "    \"\"\"\n",
    "    Save infomations of the post to a dictionary named \"news\",\n",
    "    then append \"news\" to the \"news_list\"\n",
    "    and output as json in a .txt file every 2 posts\n",
    "    \"\"\"\n",
    "    news = {}\n",
    "    resp_c = requests.get(url)\n",
    "    soup_c = BeautifulSoup(resp_c.text, 'html5lib')   \n",
    "\n",
    "    news[\"title\"]    = soup_c.select(\"h1.ts\")[0].text.replace('\\n','')\n",
    "    news[\"datetime\"] = soup_c.select('span.date-show-info')[0].text.replace('發表','').strip()\n",
    "    news[\"reporter\"] = soup_c.select('a[itemprop=\"author\"]')[0].text\n",
    "    news[\"media\"]    = \"wetalk\"\n",
    "    news[\"category\"] = \"Forum\"\n",
    "    news[\"hash\"]     = hash(resp_c.text)\n",
    "    news[\"url\"]      = url\n",
    "    news[\"content\"]  = soup_c.select(\"td.t_f > article\")[0].text.replace('\\n','').replace('發表','').strip()\n",
    "    news[\"comments\"] = []\n",
    "    for i in range(len(soup_c.select(\"td.info-post-td > a\"))):\n",
    "        news[\"comments\"].append({})   \n",
    "        news[\"comments\"][i][\"comment_content\"] = \"\".join([p.text for p in soup_c.select('[id^=\"postmessage_\"] > div[align=\"left\"]')])\n",
    "        news[\"comments\"][i][\"datetime\"] = soup_c.select(\"span.date-show-info\")[0].text.replace('\\n','').replace('發表','').strip()\n",
    "        news[\"comments\"][i][\"user_id\"] = soup_c.select(\"td.info-post-td > a\")[0].text\n",
    "    news_list.append(news)\n",
    "    count.append('SUCCESS')  #這裏我使用list做為計數器，因為list傳的是記憶體位址，各個thread執行完去append都不會出現問題\n",
    "    if 0 == len(count)%2:  #這裏改成100，每100個post輸出一次\n",
    "        output_as_json(len(count), 'wetalk', news_list)\n",
    "        news_list[:] = []\n",
    "        print('輸出一個檔案囉～')\n",
    "\n",
    "def output_as_json(index, media, x):  \n",
    "    \"\"\"\n",
    "    Write data in json format into .txt files\n",
    "    \"\"\"\n",
    "    with open(\"./News_Crawler/{}/{}_{}.txt\".format(media, media, index), 'w', encoding='UTF-8') as f:\n",
    "        jd = json.dumps(x, ensure_ascii=False, indent=4)\n",
    "        f.write(jd)\n",
    "\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(THREAD_NUM):\n",
    "    threads = ThreadPoolExecutor(THREAD_NUM)\n",
    "    \n",
    "    post_urls = []\n",
    "    futures = [threads.submit(get_url_links, page, post_urls) for page in range(1, 2)]\n",
    "    wait(futures)\n",
    "        \n",
    "    news_list = []\n",
    "    count = []\n",
    "    futures = [threads.submit(save_posts_info, post_url, news_list, count) for post_url in post_urls]\n",
    "    wait(futures)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "輸出一個檔案囉～\n",
      "main = 0:00:19.215276\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":        \n",
    "    START = datetime.now()\n",
    "    main(10)\n",
    "    print('main = ' + stop_watch()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into MongoDB_實驗區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_watch():\n",
    "    \"\"\"\n",
    "    A stop_watch to time a code segment \n",
    "    in order to monitor performance\n",
    "    \"\"\"\n",
    "    global START  #<----------------------------------不加global修飾詞會出現UnboundLocalError，但加了感覺很暴力XD\n",
    "    END = datetime.now()\n",
    "    timeSpent = str(END - START) \n",
    "\n",
    "    START = END\n",
    "    return timeSpent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url_links(page, post_urls):  \n",
    "    \"\"\"\n",
    "    Read through HTML content and returns a list of url_links\n",
    "    of each post in the category \"politics\" at Wetalk.tw\n",
    "    \"\"\"\n",
    "    URL = \"https://www.wetalk.tw/forum.php?mod=forumdisplay&fid=2&page={}\".format(page)    \n",
    "    resp = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html5lib\")\n",
    "    tmp_urls = []\n",
    "    tmp_urls.extend([a.get('href') for a in soup.select('tbody > tr > th > a.xst')])\n",
    "    post_urls += tmp_urls[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_posts_info(url, news_list, count):\n",
    "    \"\"\"\n",
    "    Save infomations of the post to a dictionary named \"news\",\n",
    "    then append \"news\" to the \"news_list\",\n",
    "    load the \"news\" record into MongoDB,\n",
    "    and finally output as json in a .txt file every 2 posts\n",
    "    \"\"\"\n",
    "    news = {}\n",
    "    resp_c = requests.get(url)\n",
    "    soup_c = BeautifulSoup(resp_c.text, 'html5lib') \n",
    "\n",
    "    news[\"title\"]    = soup_c.select(\"h1.ts\")[0].text.replace('\\n','')\n",
    "    news[\"datetime\"] = soup_c.select('span.date-show-info')[0].text.replace('發表','').strip()\n",
    "    news[\"reporter\"] = soup_c.select('a[itemprop=\"author\"]')[0].text\n",
    "    news[\"media\"]    = \"wetalk\"\n",
    "    news[\"category\"] = \"Forum\"\n",
    "    news[\"hash\"]     = hash(resp_c.text)\n",
    "    news[\"url\"]      = url\n",
    "    news[\"content\"]  = soup_c.select(\"td.t_f > article\")[0].text.replace('\\n','').replace('發表','').strip()\n",
    "    news[\"comments\"] = []\n",
    "    \n",
    "    for i in range(len(soup_c.select(\"td.info-post-td > a\"))):\n",
    "        news[\"comments\"].append({})   \n",
    "        news[\"comments\"][i][\"comment_content\"] = \"\".join([p.text for p in soup_c.select('[id^=\"postmessage_\"] > div[align=\"left\"]')])\n",
    "        news[\"comments\"][i][\"datetime\"] = soup_c.select(\"span.date-show-info\")[0].text.replace('\\n','').replace('發表','').strip()\n",
    "        news[\"comments\"][i][\"user_id\"] = soup_c.select(\"td.info-post-td > a\")[0].text\n",
    "    news_list.append(news)\n",
    "    count.append('SUCCESS')  #這裏我使用list做為計數器，因為list傳的是記憶體位址，各個thread執行完去append都不會出現問題\n",
    "    load_into_mongodb('testDatabase', 'testCollection', news)\n",
    "\n",
    "    if 0 == len(count)%2:  #這裏改成100，每100個post輸出一次\n",
    "        output_as_json(len(count), 'wetalk', news_list)\n",
    "        news_list[:] = []\n",
    "        print('輸出一個檔案囉～')\n",
    "\n",
    "def output_as_json(index, media, x):    \n",
    "    \"\"\"\n",
    "    Write data in json format into .txt files\n",
    "    \"\"\"\n",
    "    with open(\"./News_Crawler/{}/{}_{}.txt\".format(media, media, index), 'w', encoding='UTF-8') as f:\n",
    "        jd = json.dumps(x, ensure_ascii=False, indent=4)\n",
    "        f.write(jd)\n",
    "# 這裏需要注意的是資料夾要自己先建好，with open(\"...\",'w')只會幫你自動產生檔案，而不會產生資料夾\n",
    "# JSON encoder and decoder的介紹\n",
    "# https://docs.python.org/3/library/json.html\n",
    "# 了解JSON格式\n",
    "# http://j796160836.pixnet.net/blog/post/30530326-瞭解json格式\n",
    "\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_into_mongodb(db_name, collection_name, doc):\n",
    "#     \"\"\"\n",
    "#     Loads data into MongoDB\n",
    "#     \"\"\"\n",
    "#     db = client[db_name]\n",
    "#     collection = db[collection_name]\n",
    "#     collection.insert_one(doc)\n",
    "    \n",
    "# # 之後應改寫判斷條件，然後如果單筆document使用.insert_one()，多筆則使用.insert_many()\n",
    "# # 注意這裡要使用pymongo的語法，而非mongoscript，否則無法使用“變數” eg. db.collection_name.insert(record)建立的db會叫做collection_name而非tesCollection\n",
    "# # 詳見：\n",
    "# # 如何利用pymongo建立connection, db, collection: http://api.mongodb.com/python/current/tutorial.html\n",
    "# # 如何利用pymongo進行Collection level operations, eg. insert_many(): http://api.mongodb.com/python/current/api/pymongo/collection.html\n",
    "\n",
    "# # bulk_write(Requests: Requests are passed as a list of write operation instances ( InsertOne, UpdateOne, UpdateMany, ReplaceOne, DeleteOne, or DeleteMany).), insert_one(document: The document to insert.), insert_many(documents: A iterable of documents to insert.)\n",
    "# # http://api.mongodb.com/python/current/api/pymongo/collection.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_into_mongodb(db_name, collection_name, doc):\n",
    "    \"\"\"\n",
    "    Loads data into MongoDB\n",
    "    \"\"\"\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    collection.insert(doc)\n",
    "    \n",
    "# 之後應改寫判斷條件，然後如果單筆document使用.insert_one()，多筆則使用.insert_many()\n",
    "# 注意這裡要使用pymongo的語法，而非mongoscript，否則無法使用“變數” eg. db.collection_name.insert(record)建立的db會叫做collection_name而非tesCollection\n",
    "# 詳見：\n",
    "# 如何利用pymongo建立connection, db, collection: http://api.mongodb.com/python/current/tutorial.html\n",
    "# 如何利用pymongo進行Collection level operations, eg. insert_many(): http://api.mongodb.com/python/current/api/pymongo/collection.html\n",
    "\n",
    "# bulk_write(Requests: Requests are passed as a list of write operation instances ( InsertOne, UpdateOne, UpdateMany, ReplaceOne, DeleteOne, or DeleteMany).), insert_one(document: The document to insert.), insert_many(documents: A iterable of documents to insert.)\n",
    "# http://api.mongodb.com/python/current/api/pymongo/collection.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_db_data(db_name, collection_name):\n",
    "    \"\"\"\n",
    "    Query data from MongoDB,\n",
    "    and print it to the console\n",
    "    \"\"\"\n",
    "    db = client[db_name]\n",
    "   # utilize for-loop to iterate through curser-object\n",
    "    for doc in db.collection_name.find():\n",
    "        print(doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(THREAD_NUM):\n",
    "    threads = ThreadPoolExecutor(THREAD_NUM)\n",
    "    \n",
    "    post_urls = []\n",
    "    futures = [threads.submit(get_url_links, page, post_urls) for page in range(1, 2)]\n",
    "    wait(futures)\n",
    "        \n",
    "    news_list = []\n",
    "    count = []\n",
    "    futures = [threads.submit(save_posts_info, post_url, news_list, count) for post_url in post_urls]\n",
    "    wait(futures)\n",
    "    \n",
    "    #show_db_data('testDatabase', 'testCollection')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natashapan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main = 0:00:22.412879\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":        \n",
    "    START = datetime.now()\n",
    "    client = MongoClient('localhost', 27017, maxPoolSize=None) #這裡需要指名你要連線的MongoDB所在的ip和port\n",
    "    main(10)\n",
    "    print('main = ' + stop_watch()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Final Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Class WetalkCrawler():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Test():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def add(self, x, y):\n",
    "        return x+y, self.name, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "client = MongoClient('localhost',27017)\n",
    "#db_name = testDatabase\n",
    "#collection_name = testCollection\n",
    "db = client['testDatabase']\n",
    "# db.testCollection.insert({\"key\":\"value\"})\n",
    "\n",
    "with open('D:/woodnata_note/test_data') as f:\n",
    "    str_cont = f.read()\n",
    "    list_cont = json.loads(str_cont)\n",
    "    # insert a 'list' of data using method 'insert_many()'\n",
    "    # [dbname].[collection].method\n",
    "    db.testCollection.insert_many(list_cont)\n",
    "\n",
    "#we use for loop to iterate the real data from curser\n",
    "for doc in db.testCollection.find():\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving performance and profiling__實驗區"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 7 tips to Time Python scripts and control Memory & CPU usage\n",
    "    <br> http://www.marinamele.com/7-tips-to-time-python-scripts-and-control-memory-and-cpu-usage\n",
    "\n",
    "\n",
    "* google: measure performance bottleneck python\n",
    "\n",
    "\n",
    "* Performance and Profiling\n",
    "Q: What is Software Profiling?\n",
    "A: The act of using instrumentation to objectively measure the performance of your application. \n",
    "“Performance” can be a measure of any of the following:\n",
    "    1. resource use (CPU, memory)\n",
    "    2. frequency or duration of function calls\n",
    "    3. wall clock execution time of part or all of your application\n",
    "    <br>http://uwpce-pythoncert.github.io/SystemDevelopment/profiling.html\n",
    "\n",
    "\n",
    "* stopwatch.py\n",
    "    <br>https://gist.github.com/igniteflow/1253276\n",
    "\n",
    "\n",
    "* timeit.timeit()\n",
    "    <br> https://docs.python.org/3.6/library/timeit.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
